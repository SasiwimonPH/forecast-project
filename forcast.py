# -*- coding: utf-8 -*-
"""forcast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JCbaQMvAZTJDrZPgRN0DJz7WCTnrXSto
"""

# Install specific versions of packages to ensure compatibility
!pip install scipy==1.11.4 statsmodels==0.14.0 pmdarima==2.0.4 --upgrade --force-reinstall

import pandas as pd

# โหลดข้อมูล
df = pd.read_csv("sales2022_2023.csv")

df

df['Branch_id'] = df['BranchName'].str.split('-').str[0]
df = df.drop(columns=['BranchName'])
df = df[~df['Branch_id'].isin(['EK15', 'EK17','EK18','EK19','EK20'])]

df

import matplotlib.pyplot as plt
import pandas as pd

# สร้างคอลัมน์ใหม่ชื่อ YearMonth สำหรับแกน X (ปีและเดือนรวมกัน)
df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(DAY=1))
# เติม missing values
for col in ['SalesAmount', 'Bill', 'Member', 'Sales Per Visit']:
    df[col] = df[col].fillna(df[col].median())

branches = df['Branch_id'].unique()

plt.figure(figsize=(15,8))

for branch in branches:
    df_branch = df[df['Branch_id'] == branch]
    plt.plot(df_branch['Date'], df_branch['SalesAmount'], marker='o', label=branch)

    # เพิ่มป้ายตัวเลขยอดขาย
    for x, y in zip(df_branch['Date'], df_branch['SalesAmount']):
        plt.text(x, y, f'{y:,}', fontsize=9, ha='center', va='bottom', rotation=45)

plt.title('Monthly Sales Amount by Branch')
plt.xlabel('Date')
plt.ylabel('Sales Amount')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""ความสัมพันธ์ยอดขายกับปัจจัย"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# กำหนดฟีเจอร์
features = ['SalesAmount', 'Bill', 'Member', 'Sales Per Visit',
            'Promotion_disc(%)', 'Promotion_BuygetFree', 'Promotion_gift',
            'Promotion_member', 'Promotion_platfrom', 'Promotion_set']

# เติม missing values
for col in features:
    if col in df.columns:
      df[col] = df.groupby('Branch_id')[col].transform(lambda x: x.fillna(x.median()))


branches = df['Branch_id'].unique()

for branch in branches:
    df_branch = df[df['Branch_id'] == branch].copy()
    branch_features = [f for f in features if f in df_branch.columns]
    if not branch_features:
        print(f"No relevant features found for correlation in branch: {branch}")
        continue

    corr_matrix = df_branch[branch_features].corr(method='pearson')

    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
    plt.title(f'Correlation Heatmap - {branch}')
    plt.tight_layout()
    plt.show()

# โหลดไฟล์วันหยุด
holiday_df = pd.read_csv("thai_monthly_holiday_features.csv")

# รวมข้อมูลด้วย merge โดยใช้ year-month
merged_df = df.merge(holiday_df, how='left', left_on=['Year', 'Month'], right_on=['year', 'month'])

#ไม่ต้องการคอลัมน์ year กับ month ซ้ำออก
merged_df = merged_df.drop(columns=['year', 'month','major_holiday'])

merged_df

merged_df = merged_df.fillna(0)
print(merged_df.isnull().sum())

merged_df = merged_df.drop(columns=['Promotion'])

merged_df

savedata= merged_df.to_csv('merged_df.csv', index=False)

# ส่วนที่ 1: Import และเตรียมข้อมูล
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.stattools import adfuller
import pmdarima as pm

# สมมุติว่า merged_df คือ DataFrame หลักของคุณ
df = merged_df.copy()
df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(DAY=1))

if 'BranchName' not in df.columns:
    df['BranchName'] = df['Branch_id']

df = df.sort_values(['BranchName', 'Date'])

# ตั้งค่าพารามิเตอร์
features = ['Bill','Member','Sales Per Visit','Promotion_disc(%)',
            'Promotion_BuygetFree','Promotion_gift','Promotion_member',
            'Promotion_platfrom','Promotion_set','num_holidays','has_long_weekend']
target = 'SalesAmount'
correlation_threshold = 0.3

# ตัวแปรเก็บโมเดลและผลลัพธ์
mlr_models = {}
arimax_models = {}
results = []
combined_predictions = []

# ส่วนที่ 2: วนลูปฝึกโมเดลแต่ละสาขา
for branch, group in df.groupby('BranchName'):
    group = group.sort_values('Date').reset_index(drop=True)
    split_idx = int(len(group) * 0.8)
    train = group.iloc[:split_idx].reset_index(drop=True)
    test = group.iloc[split_idx:].reset_index(drop=True)

    if len(train) < 10 or len(test) < 1:
        print(f"[{branch}] Not enough data.")
        continue

    available_features = [f for f in features if f in train.columns]
    corr = train[available_features + [target]].corr(method='pearson')[target].drop(target)
    selected_features = corr[abs(corr) >= correlation_threshold].index.tolist()

    if not selected_features:
        print(f"[{branch}] No features selected.")
        continue

    X_train = train[selected_features].fillna(0)
    y_train = train[target].fillna(method='ffill')
    X_test = test[selected_features].fillna(0)
    y_test = test[target].fillna(method='ffill')

    # -------- MLR --------
    try:
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        mlr = LinearRegression()
        mlr.fit(X_train_scaled, y_train)

        y_pred_train_mlr = mlr.predict(X_train_scaled)
        y_pred_test_mlr = mlr.predict(X_test_scaled)

        mlr_models[branch] = {
            'model': mlr,
            'scaler': scaler,
            'features': selected_features
        }

        # Evaluation: MLR
        mlr_metrics = {
            'rmse_train': np.sqrt(mean_squared_error(y_train, y_pred_train_mlr)),
            'mape_train': mean_absolute_percentage_error(y_train, y_pred_train_mlr) * 100,
            'mae_train': mean_absolute_error(y_train, y_pred_train_mlr),
            'rmse_test': np.sqrt(mean_squared_error(y_test, y_pred_test_mlr)),
            'mape_test': mean_absolute_percentage_error(y_test, y_pred_test_mlr) * 100,
            'mae_test': mean_absolute_error(y_test, y_pred_test_mlr)
        }

        results.append({
            'Branch': branch,
            'Model': 'MLR',
            'Train_RMSE': mlr_metrics['rmse_train'],
            'Train_MAPE': mlr_metrics['mape_train'],
            'Train_MAE': mlr_metrics['mae_train'],
            'Test_RMSE': mlr_metrics['rmse_test'],
            'Test_MAPE': mlr_metrics['mape_test'],
            'Test_MAE': mlr_metrics['mae_test'],
            'Used_Features': ', '.join(selected_features)
        })

    except Exception as e:
        print(f"[{branch}] MLR error: {e}")
        continue

    # -------- ARIMAX --------
    try:
        diff_order = 0
        if len(y_train.dropna()) > 0:
            pval = adfuller(y_train.dropna())[1]
            diff_order = 0 if pval < 0.05 else 1

        auto_model = pm.auto_arima(y_train, exogenous=X_train, d=diff_order,
                                   seasonal=False, stepwise=True,
                                   error_action='ignore', suppress_warnings=True)
        best_order = auto_model.order

        arimax_model = SARIMAX(endog=y_train, exog=X_train, order=best_order,
                               enforce_stationarity=False, enforce_invertibility=False)
        arimax_result = arimax_model.fit(disp=False)

        y_pred_train_arimax = arimax_result.predict(start=0, end=len(train)-1, exog=X_train)
        y_pred_test_arimax = arimax_result.predict(start=len(train), end=len(train)+len(test)-1, exog=X_test)

        arimax_models[branch] = {
            'model': arimax_result,
            'features': selected_features,
            'order': best_order
        }

        # Evaluation: ARIMAX
        arimax_metrics = {
            'rmse_train': np.sqrt(mean_squared_error(y_train, y_pred_train_arimax)),
            'mape_train': mean_absolute_percentage_error(y_train, y_pred_train_arimax) * 100,
            'mae_train': mean_absolute_error(y_train, y_pred_train_arimax),
            'rmse_test': np.sqrt(mean_squared_error(y_test, y_pred_test_arimax)),
            'mape_test': mean_absolute_percentage_error(y_test, y_pred_test_arimax) * 100,
            'mae_test': mean_absolute_error(y_test, y_pred_test_arimax)
        }

        results.append({
            'Branch': branch,
            'Model': f'ARIMAX {best_order}',
            'Train_RMSE': arimax_metrics['rmse_train'],
            'Train_MAPE': arimax_metrics['mape_train'],
            'Train_MAE': arimax_metrics['mae_train'],
            'Test_RMSE': arimax_metrics['rmse_test'],
            'Test_MAPE': arimax_metrics['mape_test'],
            'Test_MAE': arimax_metrics['mae_test'],
            'Used_Features': ', '.join(selected_features)
        })

    except Exception as e:
        print(f"[{branch}] ARIMAX error: {e}")
        continue

    # -------- รวมค่าพยากรณ์ --------
    combined_df = pd.DataFrame({
        'Branch': branch,
        'Date': pd.concat([train['Date'], test['Date']]).values,
        'y_true': pd.concat([y_train, y_test]).values,
        'y_pred_mlr': np.concatenate([y_pred_train_mlr, y_pred_test_mlr]),
        'y_pred_arimax': np.concatenate([y_pred_train_arimax, y_pred_test_arimax])
    })

    combined_predictions.append(combined_df)

# ส่วนที่ 3: รวมผลลัพธ์ทั้งหมด
df_all_preds = pd.concat(combined_predictions, ignore_index=True)
df_all_preds = df_all_preds.sort_values(['Branch', 'Date']).reset_index(drop=True)

print("Combined Predictions:")
df_all_preds

# ส่วนที่ 3: รวมผลลัพธ์ทั้งหมด
df_results = pd.DataFrame(results)
df_results = df_results.sort_values(['Branch', 'Model']).reset_index(drop=True)

# แสดงตัวอย่างผลลัพธ์
print("Evaluation Summary:")
df_results

df_results[['Branch', 'Model', 'Test_RMSE', 'Test_MAPE', 'Test_MAE']]

"""🔹 MLR
ชนะใน ~73% ของสาขา

ให้ผลดีกว่า ARIMAX ใน สาขาเกือบทั้งหมด

โดยเฉพาะ Test_MAPE ต่ำมาก (< 2%) ในหลายสาขา เช่น EK02, EK04, EK05, EK11, EK13

🔸 ARIMAX
ชนะเฉพาะบางสาขา เช่น:

EK06 → RMSE, MAPE, MAE ดีกว่า

EK07 → ดีกว่าในทุกตัวชี้วัด

EK10 → RMSE และ MAE ดีกว่า

EK16 → ดีกว่าเล็กน้อยในทุกตัวชี้วัด

มีบางกรณีที่ ARIMAX แย่มาก เช่น EK05, EK11 → ค่าคาดเคลื่อนสูงกว่าหลายเท่า
"""

from sklearn.model_selection import TimeSeriesSplit

merged_df = merged_df.sort_values(['Branch_id', 'Date']).reset_index(drop=True)

n_splits = 5
tscv = TimeSeriesSplit(n_splits=n_splits)

print(f"Performing Time Series Cross-Validation with {n_splits} splits.")

cv_splits = []
for train_index, test_index in tscv.split(merged_df):
    cv_splits.append((train_index, test_index))

print(f"Generated {len(cv_splits)} splits.")

from sklearn.linear_model import LinearRegression
from statsmodels.tsa.statespace.sarimax import SARIMAX
import pmdarima as pm
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error
import numpy as np
import pandas as pd

# Define the features and target
features = ['Bill','Member','Sales Per Visit','Promotion_disc(%)', 'Promotion_BuygetFree',
             'Promotion_gift', 'Promotion_member', 'Promotion_platfrom', 'Promotion_set','num_holidays', 'has_long_weekend']
target = 'SalesAmount'

# Set correlation threshold for feature selection
correlation_threshold = 0.3

cv_results = []

for branch_name, branch_data in merged_df.groupby('Branch_id'):
    print(f"Processing branch: {branch_name}")

    # Prepare data for this branch
    branch_data = branch_data.reset_index(drop=True)
    X_all = branch_data[features].fillna(0)
    y_all = branch_data[target].fillna(method='ffill')

    if len(branch_data) < n_splits + 1:
        print(f"  Skipping branch {branch_name}: Not enough data for {n_splits} splits.")
        continue

    # --- Cross-validation loop ---
    for fold_num, (train_index, test_index) in enumerate(tscv.split(branch_data), 1):
        print(f"  Processing Fold {fold_num}/{n_splits}")

        train_fold = branch_data.iloc[train_index]
        test_fold = branch_data.iloc[test_index]

        X_train = train_fold[features].fillna(0)
        y_train = train_fold[target].fillna(method='ffill')

        X_test = test_fold[features].fillna(0)
        y_test = test_fold[target].fillna(method='ffill')


        if len(train_fold) < 2 or len(test_fold) < 1:
            print(f"    Skipping Fold {fold_num}: Not enough data in train or test split.")
            continue

        # --- Feature Selection for the current fold (based on train data) ---
        available_features_fold = [f for f in features if f in X_train.columns]
        if not available_features_fold:
             print(f"    Skipping Fold {fold_num}: No available features for correlation analysis.")
             cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': 'MLR',
                'Train_RMSE': np.nan, 'Train_MAPE': np.nan, 'Train_MAE': np.nan,
                'Test_RMSE': np.nan, 'Test_MAPE': np.nan, 'Test_MAE': np.nan,
                'Used_Features': '',
                'ARIMAX_Order': None,
                'ARIMAX_Diff_Order': np.nan
            })
             cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': 'ARIMAX',
                'Train_RMSE': np.nan, 'Train_MAPE': np.nan, 'Train_MAE': np.nan,
                'Test_RMSE': np.nan, 'Test_MAPE': np.nan, 'Test_MAE': np.nan,
                'Used_Features': '',
                'ARIMAX_Order': None,
                'ARIMAX_Diff_Order': np.nan
            })
             continue

        corr_fold = X_train[available_features_fold].corrwith(y_train)
        selected_features_fold = corr_fold[abs(corr_fold) >= correlation_threshold].index.tolist()

        if len(selected_features_fold) == 0:
            print(f"    Skipping Fold {fold_num}: No features selected based on correlation threshold.")

            cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': 'MLR',
                'Train_RMSE': np.nan, 'Train_MAPE': np.nan, 'Train_MAE': np.nan,
                'Test_RMSE': np.nan, 'Test_MAPE': np.nan, 'Test_MAE': np.nan,
                'Used_Features': '',
                'ARIMAX_Order': None,
                'ARIMAX_Diff_Order': np.nan
            })
            cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': 'ARIMAX',
                'Train_RMSE': np.nan, 'Train_MAPE': np.nan, 'Train_MAE': np.nan,
                'Test_RMSE': np.nan, 'Test_MAPE': np.nan, 'Test_MAE': np.nan,
                'Used_Features': '',
                'ARIMAX_Order': None,
                'ARIMAX_Diff_Order': np.nan
            })
            continue

        X_train_selected = X_train[selected_features_fold]
        X_test_selected = X_test[selected_features_fold]

        # --- Multiple Linear Regression for the fold ---
        try:
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train_selected)
            X_test_scaled = scaler.transform(X_test_selected)

            mlr = LinearRegression()
            mlr.fit(X_train_scaled, y_train)
            y_pred_train_mlr = mlr.predict(X_train_scaled)
            y_pred_test_mlr = mlr.predict(X_test_scaled)

            rmse_train_mlr = np.sqrt(mean_squared_error(y_train, y_pred_train_mlr))
            mape_train_mlr = mean_absolute_percentage_error(y_train, y_pred_train_mlr) * 100
            mae_train_mlr = mean_absolute_error(y_train, y_pred_train_mlr)

            rmse_test_mlr = np.sqrt(mean_squared_error(y_test, y_pred_test_mlr))
            mape_test_mlr = mean_absolute_percentage_error(y_test, y_pred_test_mlr) * 100
            mae_test_mlr = mean_absolute_error(y_test, y_pred_test_mlr)
            cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': 'MLR',
                'Train_RMSE': rmse_train_mlr,
                'Train_MAPE': mape_train_mlr,
                'Train_MAE': mae_train_mlr,
                'Test_RMSE': rmse_test_mlr,
                'Test_MAPE': mape_test_mlr,
                'Test_MAE': mae_test_mlr,
                'Used_Features': ', '.join(selected_features_fold),
                'ARIMAX_Order': None,
                'ARIMAX_Diff_Order': np.nan
            })

        except Exception as e:
            print(f"    MLR Error in Fold {fold_num} for branch {branch_name}: {e}")
            cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': 'MLR',
                'Train_RMSE': np.nan, 'Train_MAPE': np.nan, 'Train_MAE': np.nan,
                'Test_RMSE': np.nan, 'Test_MAPE': np.nan, 'Test_MAE': np.nan,
                'Used_Features': ', '.join(selected_features_fold),
                'ARIMAX_Order': None,
                'ARIMAX_Diff_Order': np.nan
            })


        # --- ARIMAX with auto_arima for the fold ---
        try:
            # ตรวจสอบ Stationarity ด้วย ADF Test
            adf_result = adfuller(y_train.dropna())
            is_stationary = adf_result[1] < 0.05
            diff_order = 0 if is_stationary else 1

            # ใช้ auto_arima หา best order
            auto_model = pm.auto_arima(
                y_train,
                exogenous=X_train_selected,
                seasonal=False,
                stepwise=True,
                d=diff_order,
                error_action='ignore',
                suppress_warnings=True,
                max_p=5, max_q=5,
                trace=False
            )
            best_order = auto_model.order

            # Fit SARIMAX
            arimax_model = SARIMAX(
                endog=y_train,
                exog=X_train_selected,
                order=best_order,
                enforce_stationarity=False,
                enforce_invertibility=False
            )
            arimax_result = arimax_model.fit(disp=False)

            # พยากรณ์
            y_pred_train_arimax = arimax_result.predict(start=0, end=len(train_fold)-1, exog=X_train_selected)
            y_pred_test_arimax = arimax_result.predict(start=len(train_fold), end=len(train_fold)+len(test_fold)-1, exog=X_test_selected)

            rmse_train_arimax = np.sqrt(mean_squared_error(y_train, y_pred_train_arimax))
            mape_train_arimax = mean_absolute_percentage_error(y_train, y_pred_train_arimax) * 100
            mae_train_arimax = mean_absolute_error(y_train, y_pred_train_arimax)

            rmse_test_arimax = np.sqrt(mean_squared_error(y_test, y_pred_test_arimax))
            mape_test_arimax = mean_absolute_percentage_error(y_test, y_pred_test_arimax) * 100
            mae_test_arimax = mean_absolute_error(y_test, y_pred_test_arimax)


            cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': f'ARIMAX {best_order}',
                'Train_RMSE': rmse_train_arimax,
                'Train_MAPE': mape_train_arimax,
                'Train_MAE': mae_train_arimax,
                'Test_RMSE': rmse_test_arimax,
                'Test_MAPE': mape_test_arimax,
                'Test_MAE': mae_test_arimax,
                'Used_Features': ', '.join(selected_features_fold),
                'ARIMAX_Order': best_order,
                'ARIMAX_Diff_Order': diff_order
            })

        except Exception as e:
            print(f"    ARIMAX Error in Fold {fold_num} for branch {branch_name}: {e}")
            cv_results.append({
                'Branch': branch_name,
                'fold': fold_num,
                'Model': 'ARIMAX',
                'Train_RMSE': np.nan, 'Train_MAPE': np.nan, 'Train_MAE': np.nan,
                'Test_RMSE': np.nan, 'Test_MAPE': np.nan, 'Test_MAE': np.nan,
                'Used_Features': ', '.join(selected_features_fold),
                'ARIMAX_Order': None,
                'ARIMAX_Diff_Order': np.nan
            })

cv_df = pd.DataFrame(cv_results)

cv_summary = cv_df.groupby(['Branch', 'Model']).agg({
    'Test_RMSE': 'mean',
    'Test_MAPE': 'mean',
    'Test_MAE': 'mean',
}).reset_index()

cv_summary

"""จากค่า Cross Validation, ARIMAX (เมื่อเลือกโมเดลที่ดีที่สุดในแต่ละสาขา) มี ผลลัพธ์เฉลี่ยดีกว่า MLR ทุกตัวชี้วัด

โดยเฉพาะ RMSE และ MAE ที่ต่ำกว่าชัดเจน แสดงว่า ARIMAX เหมาะกับชุดข้อมูลนี้ในเชิงความแม่นยำมากกว่า

แต่ต้องระวังว่า ผลของ ARIMAX แปรผันตาม parameter (p,d,q) อย่างมาก และอาจมี overfitting หรือ instability ได้ หากเลือกไม่ดี
"""

best_indices = cv_summary.loc[cv_summary.groupby('Branch')['Test_RMSE'].idxmin()].index

# Select the best models and include the 'Used_Features' column
best_models = cv_summary.loc[best_indices, ['Branch', 'Model', 'Test_RMSE', 'Test_MAPE', 'Test_MAE']].reset_index(drop=True)

# ใช้ best_indices เพื่อดึงแถวที่ตรงจาก cv_df (ซึ่งมี Used_Features อยู่แล้ว)
best_cv_rows = cv_df.loc[cv_df.groupby('Branch')['Test_RMSE'].idxmin()].reset_index(drop=True)

# รวมคอลัมน์ Used_Features เข้า best_models
best_models = cv_summary.loc[best_indices].reset_index(drop=True)
best_models['Used_Features'] = best_cv_rows['Used_Features'].values
best_models

"""บันทึกค่าจริง ค่าพยากรณ์เป็นไฟล์ csv"""

df_future = pd.read_csv("2024_pro.csv")
df_future

df_future['Branch_id'] = df_future['BranchName'].str.split('-').str[0]
df_future = df_future.drop(columns=['BranchName'])

df_future['Date'] = pd.to_datetime(df_future[['Year', 'Month']].assign(DAY=1))

# รวมข้อมูลด้วย merge โดยใช้ year-month
df_data= df_future.merge(holiday_df, how='left', left_on=['Year', 'Month'], right_on=['year', 'month'])

#ไม่ต้องการคอลัมน์ year กับ month ซ้ำออก
df_data = df_data.drop(columns=['year', 'month','major_holiday'])

df_data

for holidays in ['num_holidays', 'has_long_weekend']:
    df_data[holidays] = df_data[holidays].fillna(0).astype(int)

# 1. หาค่าเฉลี่ยใน merged_df ตามสาขา
mean_per_branch = merged_df.groupby('Branch_id')[['Bill', 'Member', 'Sales Per Visit']].mean().reset_index()

# 2. นำค่าเฉลี่ยที่ได้มา merge ลงใน df_data ตามสาขา
df_data = df_data.drop(columns=['Bill', 'Member', 'Sales Per Visit'], errors='ignore')  # ลบคอลัมน์เดิมถ้ามี
df_data = df_data.merge(mean_per_branch, on='Branch_id', how='left')

df_data

savedata= df_data.to_csv('2024_pro1.csv', index=False)

# สมมุติ df_data มีฟีเจอร์อนาคต (3 เดือนถัดไป) พร้อม
future_predictions = []

for branch, branch_data in df_data.groupby("Branch_id"):
    if branch not in mlr_models or branch not in arimax_models:
        print(f"[{branch}] ไม่มีโมเดลที่ฝึกไว้")
        continue

    branch_future = branch_data.sort_values("Date").reset_index(drop=True)
    branch_future = branch_future.head(3)

    selected_features = mlr_models[branch]['features']
    if any(f not in branch_future.columns for f in selected_features):
        print(f"[{branch}] ขาดฟีเจอร์ที่จำเป็น")
        continue

    X_future = branch_future[selected_features].fillna(0)

    # MLR
    scaler = mlr_models[branch]['scaler']
    X_scaled = scaler.transform(X_future)
    y_pred_mlr = mlr_models[branch]['model'].predict(X_scaled)

    # ARIMAX
    try:
        past_group = df[df['BranchName'] == branch].sort_values("Date")
        y_past = past_group[target].fillna(method='ffill')
        X_past = past_group[selected_features].fillna(0)

        arimax_model = SARIMAX(endog=y_past, exog=X_past, order=arimax_models[branch]['order'],
                               enforce_stationarity=False, enforce_invertibility=False)
        fitted = arimax_model.fit(disp=False)

        y_pred_arimax = fitted.predict(start=len(y_past), end=len(y_past)+len(X_future)-1, exog=X_future)

    except Exception as e:
        print(f"[{branch}] ARIMAX prediction error: {e}")
        y_pred_arimax = [np.nan] * len(X_future)

    # รวม
    pred_df = pd.DataFrame({
        'Branch': branch,
        'Date': branch_future['Date'].values,
        'y_pred_mlr': y_pred_mlr,
        'y_pred_arimax': y_pred_arimax
    })

    future_predictions.append(pred_df)

df_future_forecast = pd.concat(future_predictions, ignore_index=True)
df_future_forecast = df_future_forecast.sort_values(['Branch', 'Date']).reset_index(drop=True)

# แสดงผล
print("พยากรณ์ยอดขายล่วงหน้า 3 เดือน")
df_future_forecast

# รวมข้อมูลย้อนหลังและพยากรณ์
df_combined_all = pd.concat([df_all_preds_aligned, df_future_forecast], ignore_index=True)
df_combined_all = df_combined_all.sort_values(['Branch', 'Date']).reset_index(drop=True)

# ลบคอลัมน์ type
df_combined_all.drop(columns='type', inplace=True)

# แสดงผล
df_combined_all

!pip install --quiet gspread gspread_dataframe oauth2client

import pandas as pd
import gspread
from gspread_dataframe import set_with_dataframe
from oauth2client.service_account import ServiceAccountCredentials

import os
import json
from oauth2client.service_account import ServiceAccountCredentials

scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]

# โหลด JSON จาก environment variable
creds_json = os.environ["GCP_CREDENTIALS_JSON"]
creds_dict = json.loads(creds_json)

creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)

# เปิด Google Sheets (ใช้ชื่อไฟล์ที่แชร์ไว้กับ Service Account)
spreadsheet = client.open("Project")
sheet = spreadsheet.sheet1  # ถ้าใช้ worksheet แรก
# หรือใช้: spreadsheet.worksheet("ชื่อแผ่นงาน") ถ้ามีหลายแผ่น

# เขียน DataFrame ลงใน Google Sheet (เริ่มที่เซลล์ A1)
set_with_dataframe(sheet, df_combined_all)

print("อัปโหลด DataFrame ไปยัง Google Sheets เรียบร้อยแล้ว!")